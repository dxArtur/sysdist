## ğŸ“ Estrutura do Projeto

- **`coordinator/`**: ContÃ©m a classe principal `Coordinator.java`, responsÃ¡vel por orquestrar todo o processo MapReduce.
- **`generator/`**: Inclui `TextGenerator.java` para gerar o arquivo de dados e `ChunkSplitter.java` para dividir esse arquivo em partes menores (*chunks*).
- **`workers/`**: Abriga `MapperWorker.java` e `ReducerWorker.java`, que executam as fases de mapeamento e reduÃ§Ã£o, respectivamente.
- **`pom.xml`**: Arquivo de configuraÃ§Ã£o do Maven, gerenciando dependÃªncias e compilaÃ§Ã£o do projeto.

---

## ğŸ”„ Ordem de ExecuÃ§Ã£o

### 1. GeraÃ§Ã£o dos Dados

Execute o `TextGenerator` para criar o arquivo `data.txt` com dados de exemplo:

run as > java aplication

### 2. DivisÃ£o do Arquivo em Chunks

Execute a classe `ChunkSplitter` para dividir o arquivo `data.txt` em partes menores (chunks), por exemplo em 4 partes:

run as > java aplication
(ele vem definido para dividir em 10 arquivos)

Isso criarÃ¡ arquivos como:

```text
chunk0.txt
chunk1.txt
chunk2.txt
chunk3.txt
```
-------
### 3. ExecuÃ§Ã£o do Coordenador

Execute a classe `Coordinator` para iniciar o processo completo de MapReduce:

```bash
java coordinator.Coordinator
```

A classe `Coordinator` executa as seguintes etapas:

1. âœ… Enfileira os arquivos `chunk*.txt` no Redis como tarefas de mapeamento (`map-tasks`).
   Colocando na fila mapper_queue 10 tarefas, cada uma para processar chunk

   ApÃ³s os MapperWorkers terminarem, o Coordinator chama a classe a que inicia a fase de shuffle.

   Enfileira as tarefas para reducers, com nomes de arquivos como reducer_input_0.json.
   ### DEIXEI PRE DETERMINADO APENAS 4 REDUCERS PARA FACILITAR OS TESTES, ALTERE PARAR A MESMA QUANTIDADE DE ARQUIVOS PARA EVITAR INCONSISTÃŠNCIAS.

   ApÃ³s todos os reducers finalizarem, junta os arquivos reducer_output_0.txt a reducer_output_4.txt em um Ãºnico resultado final. 

---

### 4. ExecuÃ§Ã£o do MapperWorkers
(No eclipse)

1. Clique com o botÃ£o direito sobre ele â†’ **Run As > Java Application**
2. VÃ¡ no menu **Run > Run Configurations...**
3. Crie uma nova configuraÃ§Ã£o em **Java Application**
4. No campo **Arguments**, adicione os parÃ¢metros:

```bash
<workerId> <caminho/do/chunkX.txt>
```

**Exemplo:**
```bash
0 caminho/do/chunk0.txt
```

5. Clique em **Apply** e depois em **Run**

---

### 5. ExecuÃ§Ã£o do reducer

Segue o mesmo padrÃ£o da do mapper

exemplo de de argument.

```bash
0 reducer_0_input.json
```

Os ReducerWorkers sÃ£o iniciados em seguida. Eles leem os dados de entrada que foram preparados pelo Shuffle.

O ReducerWorker processa os dados, realizando a reduÃ§Ã£o dos valores associados a cada chave (somando, no caso).

Os resultados finais de cada ReducerWorker sÃ£o armazenados em arquivos de saÃ­da (como reducer_0_output.txt).

### ğŸ” Repita o processo para cada MapperWorker:


## âœ… Resultado Final

O arquivo `final_result.txt` conterÃ¡ as palavras encontradas no texto e o nÃºmero de ocorrÃªncias de cada uma delas.

---

## âš™ï¸ Requisitos

- Java 8+
- Redis em execuÃ§Ã£o local na porta padrÃ£o `6379`
- Maven (para compilar o projeto com `mvn package`)

---

## ğŸ“Œ ObservaÃ§Ãµes

- O Redis Ã© utilizado apenas como **sistema de fila simples** para distribuir tarefas.
- Os workers sÃ£o executados em **processos independentes** gerados pela classe `Coordinator` via `ProcessBuilder`.

---

## ğŸ‘¨â€ğŸ’» Autor Daniel Artur
